[2025-09-06 22:05:33,884] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-09-06 22:05:35,372] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-09-06 22:05:35,789] [INFO] [comm.py:821:init_distributed] cdb=None
iZ6wegwnuccb2m9s88i11lZ:75434:75434 [1] NCCL INFO cudaDriverVersion 12080
iZ6wegwnuccb2m9s88i11lZ:75434:75434 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
iZ6wegwnuccb2m9s88i11lZ:75434:75434 [1] NCCL INFO Bootstrap : Using eth0:172.26.127.41<0>
iZ6wegwnuccb2m9s88i11lZ:75434:75434 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO NET/IB : No device found.
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO NET/Socket : Using [0]eth0:172.26.127.41<0>
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO Using non-device net plugin version 0
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO Using network Socket
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO comm 0xb21a690 rank 3 nranks 4 cudaDev 1 nvmlDev 1 busId 80 commId 0xdaa3776a5ca07073 - Init START
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO comm 0xb21a690 rank 3 nRanks 4 nNodes 2 localRanks 2 localRank 1 MNNVL 0
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO P2P Chunksize set to 131072
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO Channel 00/0 : 3[1] -> 0[0] [send] via NET/Socket/0
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO Channel 01/0 : 3[1] -> 0[0] [send] via NET/Socket/0
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO Connected all rings
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO Channel 00 : 3[1] -> 2[0] via SHM/direct/direct
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO Channel 01 : 3[1] -> 2[0] via SHM/direct/direct
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO Connected all trees
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO 2 coll channels, 0 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
iZ6wegwnuccb2m9s88i11lZ:75434:75878 [1] NCCL INFO comm 0xb21a690 rank 3 nranks 4 cudaDev 1 nvmlDev 1 busId 80 commId 0xdaa3776a5ca07073 - Init COMPLETE
[2025-09-06 22:05:40,566] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 4
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO Using non-device net plugin version 0
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO Using network Socket
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO bootstrapSplit: comm 0xb643940 parent 0xb21a690 rank 3 nranks 4 color 116666945 key 3 prev 2 next 0 - DONE
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO comm 0xb643940 rank 3 nranks 4 cudaDev 1 nvmlDev 1 busId 80 commId 0xbb5232db48ae37e2 - Init START
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO comm 0xb643940 rank 3 nRanks 4 nNodes 2 localRanks 2 localRank 1 MNNVL 0
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO P2P Chunksize set to 131072
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO Channel 00/0 : 3[1] -> 0[0] [send] via NET/Socket/0
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO Channel 01/0 : 3[1] -> 0[0] [send] via NET/Socket/0
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO Connected all rings
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO Channel 00 : 3[1] -> 2[0] via SHM/direct/direct
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO Channel 01 : 3[1] -> 2[0] via SHM/direct/direct
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO Connected all trees
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO 2 coll channels, 0 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer
iZ6wegwnuccb2m9s88i11lZ:75434:76086 [1] NCCL INFO comm 0xb643940 rank 3 nranks 4 cudaDev 1 nvmlDev 1 busId 80 commId 0xbb5232db48ae37e2 - Init COMPLETE
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
Loading extension module fused_adam...
Time to load fused_adam op: 0.1009359359741211 seconds
[2025-09-06 22:05:41,222] [WARNING] [lr_schedules.py:858:get_lr] Attempting to get learning rate from scheduler before it has started
[rank3]:[E906 22:20:35.553410466 ProcessGroupNCCL.cpp:607] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=765, OpType=ALLREDUCE, NumelIn=241603584, NumelOut=241603584, Timeout(ms)=600000) ran for 600033 milliseconds before timing out.
[rank3]:[E906 22:20:35.553490158 ProcessGroupNCCL.cpp:1664] [PG 1 Rank 3] Exception (either an error or timeout) detected by watchdog at work: 765, last enqueued NCCL work: 765, last completed NCCL work: 764.
[rank3]:[E906 22:20:35.553502401 ProcessGroupNCCL.cpp:1709] [PG 1 Rank 3] Timeout at NCCL work: 765, last enqueued NCCL work: 765, last completed NCCL work: 764.
[rank3]:[E906 22:20:35.553512439 ProcessGroupNCCL.cpp:621] [Rank 3] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank3]:[E906 22:20:35.553515967 ProcessGroupNCCL.cpp:627] [Rank 3] To avoid data inconsistency, we are taking the entire process down.
[rank3]:[E906 22:20:35.554660803 ProcessGroupNCCL.cpp:1515] [PG 1 Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=765, OpType=ALLREDUCE, NumelIn=241603584, NumelOut=241603584, Timeout(ms)=600000) ran for 600033 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f2aa8977f86 in /usr/local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f2a5c3c88d2 in /usr/local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f2a5c3cf313 in /usr/local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f2a5c3d16fc in /usr/local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd8b74 (0x7f2aaa4e8b74 in /lib64/libstdc++.so.6)
frame #5: <unknown function> + 0x93fb (0x7f2ab88cb3fb in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x7f2ab85d1e83 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=765, OpType=ALLREDUCE, NumelIn=241603584, NumelOut=241603584, Timeout(ms)=600000) ran for 600033 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f2aa8977f86 in /usr/local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f2a5c3c88d2 in /usr/local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f2a5c3cf313 in /usr/local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f2a5c3d16fc in /usr/local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xd8b74 (0x7f2aaa4e8b74 in /lib64/libstdc++.so.6)
frame #5: <unknown function> + 0x93fb (0x7f2ab88cb3fb in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x7f2ab85d1e83 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1521 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f2aa8977f86 in /usr/local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5aa84 (0x7f2a5c05aa84 in /usr/local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xd8b74 (0x7f2aaa4e8b74 in /lib64/libstdc++.so.6)
frame #3: <unknown function> + 0x93fb (0x7f2ab88cb3fb in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x7f2ab85d1e83 in /lib64/libc.so.6)

